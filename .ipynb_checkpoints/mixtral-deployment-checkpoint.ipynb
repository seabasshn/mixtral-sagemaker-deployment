{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6e990e37-09db-447d-a878-cdcfe26ba9ff",
   "metadata": {},
   "source": [
    "### Mixtral Deplymeny on Amazon SageMaker\n",
    "\n",
    "Mixtral is an open LLM from Mistral AI. \n",
    "\n",
    "### Prerequisites"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4eb8b00-33b2-4ecf-b4c0-bd8c723cabe3",
   "metadata": {},
   "source": [
    "## Setup the development environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "60dbea19-b753-4279-af89-9a7be54ea7c0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /root/.config/sagemaker/config.yaml\n",
      "sagemaker role arn: arn:aws:iam::762797705265:role/service-role/AmazonSageMaker-ExecutionRole-20230323T105883\n",
      "sagemaker session region: us-west-2\n"
     ]
    }
   ],
   "source": [
    "\n",
    "## Make sure you have sagemaker>=2.199.0. If not use: !pip install \"sagemaker>=2.199.0\" --upgrade --quiet\n",
    "import sagemaker\n",
    "import boto3\n",
    "sess = sagemaker.Session()\n",
    "# sagemaker session bucket -> used for uploading data, models and logs\n",
    "# sagemaker will automatically create this bucket if it not exists\n",
    "sagemaker_session_bucket=None\n",
    "if sagemaker_session_bucket is None and sess is not None:\n",
    "    # set to default bucket if a bucket name is not given\n",
    "    sagemaker_session_bucket = sess.default_bucket()\n",
    "\n",
    "try:\n",
    "    role = sagemaker.get_execution_role()\n",
    "except ValueError:\n",
    "    iam = boto3.client('iam')\n",
    "    role = iam.get_role(RoleName='sagemaker_execution_role')['Role']['Arn']\n",
    "\n",
    "sess = sagemaker.Session(default_bucket=sagemaker_session_bucket)\n",
    "\n",
    "print(f\"sagemaker role arn: {role}\")\n",
    "print(f\"sagemaker session region: {sess.boto_region_name}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "747f2432-aaa6-4aea-8eed-64cb6983a95c",
   "metadata": {},
   "source": [
    "## Retrieve the HF LLM DLC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5fa78c74-9927-4712-ad87-95d87ac49c58",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "llm image uri: 763104351884.dkr.ecr.us-west-2.amazonaws.com/huggingface-pytorch-tgi-inference:2.1.1-tgi1.3.1-gpu-py310-cu121-ubuntu20.04-v1.0\n"
     ]
    }
   ],
   "source": [
    "# COMMENT IN WHEN PR (https://github.com/aws/sagemaker-python-sdk/pull/4314) IS MERGED\n",
    "# from sagemaker.huggingface import get_huggingface_llm_image_uri\n",
    "\n",
    "# # retrieve the llm image uri\n",
    "# llm_image = get_huggingface_llm_image_uri(\n",
    "#   \"huggingface\",\n",
    "#   version=\"1.3.1\"\n",
    "# )\n",
    "\n",
    "region_mapping = {\n",
    "    \"af-south-1\": \"626614931356\",\n",
    "    \"il-central-1\": \"780543022126\",\n",
    "    \"ap-east-1\": \"871362719292\",\n",
    "    \"ap-northeast-1\": \"763104351884\",\n",
    "    \"ap-northeast-2\": \"763104351884\",\n",
    "    \"ap-northeast-3\": \"364406365360\",\n",
    "    \"ap-south-1\": \"763104351884\",\n",
    "    \"ap-south-2\": \"772153158452\",\n",
    "    \"ap-southeast-1\": \"763104351884\",\n",
    "    \"ap-southeast-2\": \"763104351884\",\n",
    "    \"ap-southeast-3\": \"907027046896\",\n",
    "    \"ap-southeast-4\": \"457447274322\",\n",
    "    \"ca-central-1\": \"763104351884\",\n",
    "    \"cn-north-1\": \"727897471807\",\n",
    "    \"cn-northwest-1\": \"727897471807\",\n",
    "    \"eu-central-1\": \"763104351884\",\n",
    "    \"eu-central-2\": \"380420809688\",\n",
    "    \"eu-north-1\": \"763104351884\",\n",
    "    \"eu-west-1\": \"763104351884\",\n",
    "    \"eu-west-2\": \"763104351884\",\n",
    "    \"eu-west-3\": \"763104351884\",\n",
    "    \"eu-south-1\": \"692866216735\",\n",
    "    \"eu-south-2\": \"503227376785\",\n",
    "    \"me-south-1\": \"217643126080\",\n",
    "    \"me-central-1\": \"914824155844\",\n",
    "    \"sa-east-1\": \"763104351884\",\n",
    "    \"us-east-1\": \"763104351884\",\n",
    "    \"us-east-2\": \"763104351884\",\n",
    "    \"us-gov-east-1\": \"446045086412\",\n",
    "    \"us-gov-west-1\": \"442386744353\",\n",
    "    \"us-iso-east-1\": \"886529160074\",\n",
    "    \"us-isob-east-1\": \"094389454867\",\n",
    "    \"us-west-1\": \"763104351884\",\n",
    "    \"us-west-2\": \"763104351884\",\n",
    "}\n",
    "\n",
    "llm_image = f\"{region_mapping[sess.boto_region_name]}.dkr.ecr.{sess.boto_region_name}.amazonaws.com/huggingface-pytorch-tgi-inference:2.1.1-tgi1.3.1-gpu-py310-cu121-ubuntu20.04-v1.0\"\n",
    "\n",
    "# print ecr image uri\n",
    "print(f\"llm image uri: {llm_image}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2020ca0-4445-4a83-9dcd-f0a4a7cb914f",
   "metadata": {},
   "source": [
    "## Deploy Mixtral 8x7B to Amazon SageMaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "019605c8-31c6-48b9-ad76-525f7f2aacb1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from sagemaker.huggingface import HuggingFaceModel\n",
    "\n",
    "# sagemaker config\n",
    "instance_type = \"ml.g5.48xlarge\"\n",
    "number_of_gpu = 8\n",
    "health_check_timeout = 600\n",
    "\n",
    "# Define Model and Endpoint configuration parameter\n",
    "config = {\n",
    "  'HF_MODEL_ID': \"mistralai/Mixtral-8x7B-Instruct-v0.1\", # model_id from hf.co/models\n",
    "  'SM_NUM_GPUS': json.dumps(number_of_gpu), # Number of GPU used per replica\n",
    "  'MAX_INPUT_LENGTH': json.dumps(24000),  # Max length of input text\n",
    "  'MAX_BATCH_PREFILL_TOKENS': json.dumps(32000),  # Number of tokens for the prefill operation.\n",
    "  'MAX_TOTAL_TOKENS': json.dumps(32000),  # Max length of the generation (including input text)\n",
    "  'MAX_BATCH_TOTAL_TOKENS': json.dumps(512000),  # Limits the number of tokens that can be processed in parallel during the generation\n",
    "  # ,'HF_MODEL_QUANTIZE': \"awq\", # comment in to quantize not supported yet\n",
    "}\n",
    "\n",
    "# create HuggingFaceModel with the image uri\n",
    "llm_model = HuggingFaceModel(\n",
    "  role=role,\n",
    "  image_uri=llm_image,\n",
    "  env=config\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "98d3c239-ca07-42b1-8ef7-469d15fe8700",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------!"
     ]
    }
   ],
   "source": [
    "# Deploy model to an endpoint\n",
    "# https://sagemaker.readthedocs.io/en/stable/api/inference/model.html#sagemaker.model.Model.deploy\n",
    "llm = llm_model.deploy(\n",
    "  initial_instance_count=1,\n",
    "  instance_type=instance_type,\n",
    "  container_startup_health_check_timeout=health_check_timeout, # 10 minutes to be able to load the model\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20f4ae6f-691d-4d00-b02a-78b62100fd5c",
   "metadata": {},
   "source": [
    "## Run an inference and have a conversation with the model\n",
    "\n",
    "The mistralai/Mixtral-8x7B-Instruct-v0.1 is a conversational chat model meaning we can chat with it using the following prompt:\n",
    "\n",
    "``<s> [INST] User Instruction 1 [/INST] Model answer 1</s> [INST] User instruction 2 [/INST]``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3f254218-3e26-48aa-973d-bffac71e6835",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Prompt to generate\n",
    "prompt=f\"<s> [INST] What are some of the best activites at Big Bend National Park? List 10. [/INST] \"\n",
    "\n",
    "# Generation arguments\n",
    "payload = {\n",
    "    \"do_sample\": True,\n",
    "    \"top_p\": 0.6,\n",
    "    \"temperature\": 0.9,\n",
    "    \"top_k\": 50,\n",
    "    \"max_new_tokens\": 1024,\n",
    "    \"repetition_penalty\": 1.03,\n",
    "    \"return_full_text\": False,\n",
    "    \"stop\": [\"</s>\"]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4fc86e24-de4c-480e-99b0-224ec51478d9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Hiking: Big Bend National Park has over 150 miles of hiking trails, ranging from easy walks to strenuous backcountry treks. Some popular hikes include the Window Trail, the South Rim Trail, and the Lost Mine Trail.\n",
      "\n",
      "2. Backpacking: For those looking for a more remote and rugged experience, Big Bend offers numerous backpacking opportunities. Permits are required for overnight trips, and rangers recommend that all backpackers be well-prepared and experienced.\n",
      "\n",
      "3. Scenic Drives: The park has several scenic drives, including the Ross Maxwell Scenic Drive, which offers views of the Chisos Mountains, the Santa Elena Canyon, and the Rio Grande.\n",
      "\n",
      "4. River Trips: The Rio Grande runs through the park, offering opportunities for rafting, canoeing, and kayaking. Several companies offer guided trips, or visitors can bring their own equipment and launch from one of the park's designated river access points.\n",
      "\n",
      "5. Stargazing: Big Bend is known for its dark skies, making it an excellent spot for stargazing. The park offers ranger-led programs and has several designated dark-sky viewing areas.\n",
      "\n",
      "6. Wildlife Viewing: Big Bend is home to a diverse array of wildlife, including black bears, mountain lions, and javelinas. Visitors may also see a variety of birds, reptiles, and amphibians.\n",
      "\n",
      "7. Horseback Riding: Horseback riding is permitted on many of the park's trails, and several outfitters offer guided rides.\n",
      "\n",
      "8. Photography: With its stunning landscapes and diverse wildlife, Big Bend is a photographer's paradise. Visitors can take their own photos or join a ranger-led photography program.\n",
      "\n",
      "9. Birdwatching: Big Bend is home to over 450 species of birds, making it a popular destination for birdwatchers. The park offers several birdwatching programs and has several designated birdwatching areas.\n",
      "\n",
      "10. Visitor Centers: The park has several visitor centers, including the Panther Junction Visitor Center, the Chisos Basin Visitor Center, and the Castolon Visitor Center. These centers offer exhibits, ranger-led programs, and information about the park's history, geology, and wildlife.\n"
     ]
    }
   ],
   "source": [
    "chat = llm.predict({\"inputs\":prompt, \"parameters\":payload})\n",
    "\n",
    "print(chat[0][\"generated_text\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ecbe23f-44ff-4808-b6ef-e51fdca654e3",
   "metadata": {},
   "source": [
    "## Clean up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e46f28c-8c6f-480f-9c37-42f177c2902e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# llm.delete_model()\n",
    "# llm.delete_endpoint()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ee08ee6-94f4-4ccd-bd6a-0e019219d1cd",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "---------------------------------------------------------------------------\n",
    "UnexpectedStatusException                 Traceback (most recent call last)\n",
    "Cell In[7], line 3\n",
    "      1 # Deploy model to an endpoint\n",
    "      2 # https://sagemaker.readthedocs.io/en/stable/api/inference/model.html#sagemaker.model.Model.deploy\n",
    "----> 3 llm = llm_model.deploy(\n",
    "      4   initial_instance_count=1,\n",
    "      5   instance_type=instance_type,\n",
    "      6   container_startup_health_check_timeout=health_check_timeout, # 10 minutes to be able to load the model\n",
    "      7 )\n",
    "\n",
    "File /opt/conda/lib/python3.10/site-packages/sagemaker/huggingface/model.py:315, in HuggingFaceModel.deploy(self, initial_instance_count, instance_type, serializer, deserializer, accelerator_type, endpoint_name, tags, kms_key, wait, data_capture_config, async_inference_config, serverless_inference_config, volume_size, model_data_download_timeout, container_startup_health_check_timeout, inference_recommendation_id, explainer_config, **kwargs)\n",
    "    308     inference_tool = \"neuron\" if instance_type.startswith(\"ml.inf1\") else \"neuronx\"\n",
    "    309     self.image_uri = self.serving_image_uri(\n",
    "    310         region_name=self.sagemaker_session.boto_session.region_name,\n",
    "    311         instance_type=instance_type,\n",
    "    312         inference_tool=inference_tool,\n",
    "    313     )\n",
    "--> 315 return super(HuggingFaceModel, self).deploy(\n",
    "    316     initial_instance_count,\n",
    "    317     instance_type,\n",
    "    318     serializer,\n",
    "    319     deserializer,\n",
    "    320     accelerator_type,\n",
    "    321     endpoint_name,\n",
    "    322     tags,\n",
    "    323     kms_key,\n",
    "    324     wait,\n",
    "    325     data_capture_config,\n",
    "    326     async_inference_config,\n",
    "    327     serverless_inference_config,\n",
    "    328     volume_size=volume_size,\n",
    "    329     model_data_download_timeout=model_data_download_timeout,\n",
    "    330     container_startup_health_check_timeout=container_startup_health_check_timeout,\n",
    "    331     inference_recommendation_id=inference_recommendation_id,\n",
    "    332     explainer_config=explainer_config,\n",
    "    333     endpoint_logging=kwargs.get(\"endpoint_logging\", False),\n",
    "    334     endpoint_type=kwargs.get(\"endpoint_type\", None),\n",
    "    335     resources=kwargs.get(\"resources\", None),\n",
    "    336     managed_instance_scaling=kwargs.get(\"managed_instance_scaling\", None),\n",
    "    337 )\n",
    "\n",
    "File /opt/conda/lib/python3.10/site-packages/sagemaker/model.py:1653, in Model.deploy(self, initial_instance_count, instance_type, serializer, deserializer, accelerator_type, endpoint_name, tags, kms_key, wait, data_capture_config, async_inference_config, serverless_inference_config, volume_size, model_data_download_timeout, container_startup_health_check_timeout, inference_recommendation_id, explainer_config, accept_eula, endpoint_logging, resources, endpoint_type, managed_instance_scaling, **kwargs)\n",
    "   1650 if is_explainer_enabled:\n",
    "   1651     explainer_config_dict = explainer_config._to_request_dict()\n",
    "-> 1653 self.sagemaker_session.endpoint_from_production_variants(\n",
    "   1654     name=self.endpoint_name,\n",
    "   1655     production_variants=[production_variant],\n",
    "   1656     tags=tags,\n",
    "   1657     kms_key=kms_key,\n",
    "   1658     wait=wait,\n",
    "   1659     data_capture_config_dict=data_capture_config_dict,\n",
    "   1660     explainer_config_dict=explainer_config_dict,\n",
    "   1661     async_inference_config_dict=async_inference_config_dict,\n",
    "   1662     live_logging=endpoint_logging,\n",
    "   1663 )\n",
    "   1665 if self.predictor_cls:\n",
    "   1666     predictor = self.predictor_cls(self.endpoint_name, self.sagemaker_session)\n",
    "\n",
    "File /opt/conda/lib/python3.10/site-packages/sagemaker/session.py:5331, in Session.endpoint_from_production_variants(self, name, production_variants, tags, kms_key, wait, data_capture_config_dict, async_inference_config_dict, explainer_config_dict, live_logging, vpc_config, enable_network_isolation, role)\n",
    "   5328 LOGGER.info(\"Creating endpoint-config with name %s\", name)\n",
    "   5329 self.sagemaker_client.create_endpoint_config(**config_options)\n",
    "-> 5331 return self.create_endpoint(\n",
    "   5332     endpoint_name=name,\n",
    "   5333     config_name=name,\n",
    "   5334     tags=endpoint_tags,\n",
    "   5335     wait=wait,\n",
    "   5336     live_logging=live_logging,\n",
    "   5337 )\n",
    "\n",
    "File /opt/conda/lib/python3.10/site-packages/sagemaker/session.py:4242, in Session.create_endpoint(self, endpoint_name, config_name, tags, wait, live_logging)\n",
    "   4238 self.sagemaker_client.create_endpoint(\n",
    "   4239     EndpointName=endpoint_name, EndpointConfigName=config_name, Tags=tags\n",
    "   4240 )\n",
    "   4241 if wait:\n",
    "-> 4242     self.wait_for_endpoint(endpoint_name, live_logging=live_logging)\n",
    "   4243 return endpoint_name\n",
    "\n",
    "File /opt/conda/lib/python3.10/site-packages/sagemaker/session.py:4974, in Session.wait_for_endpoint(self, endpoint, poll, live_logging)\n",
    "   4968     if \"CapacityError\" in str(reason):\n",
    "   4969         raise exceptions.CapacityError(\n",
    "   4970             message=message,\n",
    "   4971             allowed_statuses=[\"InService\"],\n",
    "   4972             actual_status=status,\n",
    "   4973         )\n",
    "-> 4974     raise exceptions.UnexpectedStatusException(\n",
    "   4975         message=message,\n",
    "   4976         allowed_statuses=[\"InService\"],\n",
    "   4977         actual_status=status,\n",
    "   4978     )\n",
    "   4979 return desc\n",
    "\n",
    "UnexpectedStatusException: Error hosting endpoint huggingface-pytorch-tgi-inference-2023-12-14-21-18-04-022: Failed. Reason: The primary container for production variant AllTraffic did not pass the ping health check. Please check CloudWatch logs for this endpoint.. Try changing the instance type or reference the troubleshooting page https://docs.aws.amazon.com/sagemaker/latest/dg/async-inference-troubleshooting.html"
   ]
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 57,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.trn1.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 58,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1.32xlarge",
    "vcpuNum": 128
   },
   {
    "_defaultOrder": 59,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1n.32xlarge",
    "vcpuNum": 128
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science 3.0)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-west-2:236514542706:image/sagemaker-data-science-310-v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
